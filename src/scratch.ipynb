{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017945099862100845\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def parse_img(d):\n",
    "    d[\"img\"] = tfio.experimental.image.decode_tiff(tf.io.read_file(d[\"image_file\"]))\n",
    "#     d[\"encoding\"] = tf.strings.to_number(tf.strings.split(d[\"encoding\"], \" \"), tf.int64)\n",
    "    d[\"mask\"] = rle_decode_tf(d[\"encoding\"], (d[\"width_pixels\"], d[\"height_pixels\"]))\n",
    "    return d\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def rle_decode_tf(mask_rle, shape):\n",
    "    size = tf.math.reduce_prod(shape)\n",
    "    # Split string\n",
    "    s = tf.strings.split(mask_rle)\n",
    "    s = tf.strings.to_number(s, tf.int64)\n",
    "    # Get starts and lengths\n",
    "    starts = s[::2] - 1\n",
    "    lens = s[1::2]\n",
    "    # Make ones to be scattered\n",
    "    total_ones = tf.reduce_sum(lens)\n",
    "    ones = tf.ones([total_ones], tf.uint8)\n",
    "    # Make scattering indices\n",
    "    r = tf.range(total_ones)\n",
    "    lens_cum = tf.math.cumsum(lens)\n",
    "    s = tf.searchsorted(lens_cum, r, \"right\")\n",
    "    idx = r + tf.gather(starts - tf.pad(lens_cum[:-1], [(1, 0)]), s)\n",
    "    # Scatter ones into flattened mask\n",
    "    mask_flat = tf.scatter_nd(tf.expand_dims(idx, 1), ones, [size])\n",
    "    # Reshape into mask\n",
    "    return tf.reshape(mask_flat, shape)\n",
    "\n",
    "    \n",
    "metadata = pd.read_csv(\"../data/HuBMAP-20-dataset_information.csv\")\n",
    "metadata[\"id\"] = metadata[\"image_file\"].str.rstrip(\".tiff\")\n",
    "targets = pd.read_csv(\"../data/train.csv\")\n",
    "targets = targets.merge(metadata, on=\"id\")\n",
    "for k in [\"image_file\", \"anatomical_structures_segmention_file\", \"glomerulus_segmentation_file\"]:\n",
    "    targets[k] = \"../data/train/\" + targets[k]\n",
    "data = tf.data.Dataset.from_tensor_slices(dict(targets))\n",
    "data = data.map(parse_img)\n",
    "for i in data.take(1).as_numpy_iterator():\n",
    "    print(i[\"mask\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>encoding</th>\n",
       "      <th>image_file</th>\n",
       "      <th>width_pixels</th>\n",
       "      <th>height_pixels</th>\n",
       "      <th>anatomical_structures_segmention_file</th>\n",
       "      <th>glomerulus_segmentation_file</th>\n",
       "      <th>patient_number</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>weight_kilograms</th>\n",
       "      <th>height_centimeters</th>\n",
       "      <th>bmi_kg/m^2</th>\n",
       "      <th>laterality</th>\n",
       "      <th>percent_cortex</th>\n",
       "      <th>percent_medulla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaa6a05cc</td>\n",
       "      <td>30989109 59 31007591 64 31026074 68 31044556 7...</td>\n",
       "      <td>../data/train/aaa6a05cc.tiff</td>\n",
       "      <td>13013</td>\n",
       "      <td>18484</td>\n",
       "      <td>../data/train/aaa6a05cc-anatomical-structure.json</td>\n",
       "      <td>../data/train/aaa6a05cc.json</td>\n",
       "      <td>65631</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Female</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Left</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cb2d976f4</td>\n",
       "      <td>78144363 5 78179297 15 78214231 25 78249165 35...</td>\n",
       "      <td>../data/train/cb2d976f4.tiff</td>\n",
       "      <td>49548</td>\n",
       "      <td>34940</td>\n",
       "      <td>../data/train/cb2d976f4-anatomical-structure.json</td>\n",
       "      <td>../data/train/cb2d976f4.json</td>\n",
       "      <td>67548</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>79.9</td>\n",
       "      <td>190.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Right</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0486052bb</td>\n",
       "      <td>101676003 6 101701785 8 101727568 9 101753351 ...</td>\n",
       "      <td>../data/train/0486052bb.tiff</td>\n",
       "      <td>34937</td>\n",
       "      <td>25784</td>\n",
       "      <td>../data/train/0486052bb-anatomical-structure.json</td>\n",
       "      <td>../data/train/0486052bb.json</td>\n",
       "      <td>67177</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>180.3</td>\n",
       "      <td>32.6</td>\n",
       "      <td>Right</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e79de561c</td>\n",
       "      <td>7464094 14 7480273 41 7496453 67 7512632 82 75...</td>\n",
       "      <td>../data/train/e79de561c.tiff</td>\n",
       "      <td>27020</td>\n",
       "      <td>16180</td>\n",
       "      <td>../data/train/e79de561c-anatomical-structure.json</td>\n",
       "      <td>../data/train/e79de561c.json</td>\n",
       "      <td>67026</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Male</td>\n",
       "      <td>53</td>\n",
       "      <td>73.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>Left</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54f2eec69</td>\n",
       "      <td>124601765 36 124632133 109 124662536 147 12469...</td>\n",
       "      <td>../data/train/54f2eec69.tiff</td>\n",
       "      <td>22240</td>\n",
       "      <td>30440</td>\n",
       "      <td>../data/train/54f2eec69-anatomical-structure.json</td>\n",
       "      <td>../data/train/54f2eec69.json</td>\n",
       "      <td>67548</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>79.9</td>\n",
       "      <td>190.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Right</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1e2425f28</td>\n",
       "      <td>49453112 7 49479881 22 49506657 31 49533433 40...</td>\n",
       "      <td>../data/train/1e2425f28.tiff</td>\n",
       "      <td>32220</td>\n",
       "      <td>26780</td>\n",
       "      <td>../data/train/1e2425f28-anatomical-structure.json</td>\n",
       "      <td>../data/train/1e2425f28.json</td>\n",
       "      <td>63921</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>131.5</td>\n",
       "      <td>193.0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>Right</td>\n",
       "      <td>65</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           encoding  \\\n",
       "0  aaa6a05cc  30989109 59 31007591 64 31026074 68 31044556 7...   \n",
       "1  cb2d976f4  78144363 5 78179297 15 78214231 25 78249165 35...   \n",
       "2  0486052bb  101676003 6 101701785 8 101727568 9 101753351 ...   \n",
       "3  e79de561c  7464094 14 7480273 41 7496453 67 7512632 82 75...   \n",
       "4  54f2eec69  124601765 36 124632133 109 124662536 147 12469...   \n",
       "5  1e2425f28  49453112 7 49479881 22 49506657 31 49533433 40...   \n",
       "\n",
       "                     image_file  width_pixels  height_pixels  \\\n",
       "0  ../data/train/aaa6a05cc.tiff         13013          18484   \n",
       "1  ../data/train/cb2d976f4.tiff         49548          34940   \n",
       "2  ../data/train/0486052bb.tiff         34937          25784   \n",
       "3  ../data/train/e79de561c.tiff         27020          16180   \n",
       "4  ../data/train/54f2eec69.tiff         22240          30440   \n",
       "5  ../data/train/1e2425f28.tiff         32220          26780   \n",
       "\n",
       "               anatomical_structures_segmention_file  \\\n",
       "0  ../data/train/aaa6a05cc-anatomical-structure.json   \n",
       "1  ../data/train/cb2d976f4-anatomical-structure.json   \n",
       "2  ../data/train/0486052bb-anatomical-structure.json   \n",
       "3  ../data/train/e79de561c-anatomical-structure.json   \n",
       "4  ../data/train/54f2eec69-anatomical-structure.json   \n",
       "5  ../data/train/1e2425f28-anatomical-structure.json   \n",
       "\n",
       "   glomerulus_segmentation_file  patient_number                       race  \\\n",
       "0  ../data/train/aaa6a05cc.json           65631                      White   \n",
       "1  ../data/train/cb2d976f4.json           67548  Black or African American   \n",
       "2  ../data/train/0486052bb.json           67177                      White   \n",
       "3  ../data/train/e79de561c.json           67026  Black or African American   \n",
       "4  ../data/train/54f2eec69.json           67548  Black or African American   \n",
       "5  ../data/train/1e2425f28.json           63921                      White   \n",
       "\n",
       "                ethnicity     sex  age  weight_kilograms  height_centimeters  \\\n",
       "0  Not Hispanic or Latino  Female   73               NaN                 NaN   \n",
       "1  Not Hispanic or Latino    Male   58              79.9               190.5   \n",
       "2  Not Hispanic or Latino    Male   31             106.1               180.3   \n",
       "3  Not Hispanic or Latino    Male   53              73.0               166.0   \n",
       "4  Not Hispanic or Latino    Male   58              79.9               190.5   \n",
       "5  Not Hispanic or Latino    Male   48             131.5               193.0   \n",
       "\n",
       "   bmi_kg/m^2 laterality  percent_cortex  percent_medulla  \n",
       "0         NaN       Left              75               25  \n",
       "1        22.0      Right              75               25  \n",
       "2        32.6      Right              80               20  \n",
       "3        26.5       Left              55               45  \n",
       "4        22.0      Right              75               25  \n",
       "5        35.3      Right              65               35  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'encoding', 'image_file', 'width_pixels', 'height_pixels', 'anatomical_structures_segmention_file', 'glomerulus_segmentation_file', 'patient_number', 'race', 'ethnicity', 'sex', 'age', 'weight_kilograms', 'height_centimeters', 'bmi_kg/m^2', 'laterality', 'percent_cortex', 'percent_medulla', 'img'])\n"
     ]
    }
   ],
   "source": [
    "for i in data.as_numpy_iterator():\n",
    "    print(i.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pandas.io.json._normalize._json_normalize(data: Union[Dict, List[Dict]], record_path: Union[str, List, NoneType] = None, meta: Union[str, List[Union[str, List[str]]], NoneType] = None, meta_prefix: Union[str, NoneType] = None, record_prefix: Union[str, NoneType] = None, errors: str = 'raise', sep: str = '.', max_level: Union[int, NoneType] = None) -> 'DataFrame'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
